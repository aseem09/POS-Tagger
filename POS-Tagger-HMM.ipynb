{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from reader import parse_data, list_to_freq_dict, parse_data_test\n",
    "import xml.etree.ElementTree as ET\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import pickle\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "import time\n",
    "from numpy import asarray\n",
    "from numpy import savetxt\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(file):\n",
    "    \n",
    "    tree = ET.parse(file)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    data = []\n",
    "    labels = []\n",
    "    \n",
    "    for s_tag in root.iter('s'):\n",
    "        \n",
    "        sentence = []\n",
    "        tags = []\n",
    "        \n",
    "        for w_tag in s_tag.iterfind('w'):\n",
    "            \n",
    "            word = w_tag.text.replace(\" \", \"\")\n",
    "            tag = w_tag.attrib['c5']\n",
    "\n",
    "            sentence.append(word)\n",
    "            tags.append(tag)\n",
    "        \n",
    "        data.append(sentence)\n",
    "        labels.append(tags)\n",
    "\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path, training=True):\n",
    "\n",
    "    if training == True:\n",
    "        train_data = []\n",
    "        train_labels = []\n",
    "        \n",
    "        for subdir, dirs, files in os.walk(path):\n",
    "            for file in files:\n",
    "\n",
    "                fileName = subdir + '/' + str(file)\n",
    "                data, labels = parse_data(fileName)\n",
    "                train_data.extend(data)\n",
    "                train_labels.extend(labels)\n",
    "            \n",
    "        return train_data, train_labels\n",
    "        \n",
    "    else:\n",
    "        all_tuples = []\n",
    "        \n",
    "        for subdir, dirs, files in os.walk(path):\n",
    "            for file in files:\n",
    "\n",
    "                fileName = subdir + '/' + str(file)\n",
    "                tuples = parse_data_test(fileName)\n",
    "                all_tuples.extend(tuples)\n",
    "\n",
    "        return all_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "\n",
    "train_path = 'Train-corpus/'\n",
    "test_path = 'Test-corpus/'\n",
    "\n",
    "data, labels = load_dataset(train_path, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "483629\n",
      "483629\n",
      "['Wonder', 'boy', \"'s\", 'eyes', 'on', 'Wembley']\n",
      "['VVB-NN1', 'NN1', 'POS', 'NN2', 'PRP', 'NP0']\n"
     ]
    }
   ],
   "source": [
    "print(len(data))\n",
    "print(len(labels))\n",
    "\n",
    "print(data[0])\n",
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "dkES1f_ROwPn"
   },
   "outputs": [],
   "source": [
    "# Load JSON Files\n",
    "\n",
    "with open('words.json') as f:\n",
    "    word_dict = json.load(f)\n",
    "with open('tags.json') as f:\n",
    "    tag_dict = json.load(f)\n",
    "with open('word_tags.json') as f:\n",
    "    word_tags_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "R6XVaCmZOwPs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n",
      "192634\n",
      "252564\n"
     ]
    }
   ],
   "source": [
    "print(len(tag_dict))\n",
    "print(len(word_dict))\n",
    "print(len(word_tags_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_word_tag_freq_matrix():\n",
    "    \n",
    "    rows = len(word_dict.keys())\n",
    "    cols = len(tag_dict.keys())\n",
    "    \n",
    "    mat = [[0 for i in range(cols)] for j in range(rows)] \n",
    "    \n",
    "    i=0\n",
    "    for word in word_dict.keys():\n",
    "        j=0\n",
    "        for tag in tag_dict.keys():\n",
    "            case = word + \"_\" + tag\n",
    "            if case in word_tags_dict.keys():\n",
    "                mat[i][j] = word_tags_dict[case]\n",
    "            j = j + 1\n",
    "        i = i + 1\n",
    "        \n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_matrix = compute_word_tag_freq_matrix()\n",
    "savetxt('data.csv', freq_matrix, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_emission_prob_matrix(freq):\n",
    "    rows = len(freq_matrix)\n",
    "    cols = len(freq_matrix[0])\n",
    "    mat = np.array(freq)\n",
    "    \n",
    "    for j in range(0, cols):\n",
    "        total = sum(mat[:, j])\n",
    "        mat[:, j] = [x/total for x in mat[:, j]]\n",
    "    \n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "emission_mat = compute_emission_prob_matrix(freq_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_transition_prob_matrix(freq):\n",
    "    rows = len(freq_matrix)\n",
    "    cols = len(freq_matrix[0])\n",
    "    \n",
    "    mat = np.array(freq, dtype=float)\n",
    "    \n",
    "    for i in range(0, rows):\n",
    "        \n",
    "        total = float(sum(mat[i]))\n",
    "        if total == 0:\n",
    "            total = 1\n",
    "            \n",
    "        mat[i] = [x/total for x in mat[i]]\n",
    "            \n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_mat = compute_transition_prob_matrix(freq_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['VBB', 'DPS', 'VDG', 'VBG', 'VBD', 'VBI', 'VDZ', 'AV0', 'VBN', 'VDB', 'VHI', 'VDD', 'CRD', 'VHD', 'VDI', 'VBZ', 'DTQ', 'VDN', 'NP0', 'VM0', 'VHB', 'PRF', 'VVZ', 'AJ0', 'VHZ', 'POS', 'VVN', 'PRP', 'VVI', 'VVG', 'VVD', 'VVB', 'XX0', 'EX0', 'CJC', 'AJS', 'VHG', 'ZZ0', 'UNC', 'CJS', 'AJC', 'NN2', 'CJT', 'NN0', 'PNX', 'ITJ', 'PNQ', 'PNP', 'TO0', 'AVP', 'AVQ', 'PNI', 'VHN', 'AT0', 'ORD', 'DT0', 'NN1'])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
