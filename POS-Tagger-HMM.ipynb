{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import pickle\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "import time\n",
    "from numpy import asarray\n",
    "from numpy import savetxt\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "def get_column(list_, n):\n",
    "    return map(operator.itemgetter(n), list_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(file):\n",
    "    \n",
    "    tree = ET.parse(file)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    data = []\n",
    "    labels = []\n",
    "    \n",
    "    for s_tag in root.iter('s'):\n",
    "        \n",
    "        sentence = []\n",
    "        tags = []\n",
    "        \n",
    "        for e_tag in s_tag:\n",
    "            \n",
    "            if e_tag.tag == 'w':\n",
    "                word = e_tag.text.replace(\" \", \"\")\n",
    "                tag = e_tag.attrib['c5']\n",
    "                    \n",
    "                sentence.append(word)\n",
    "                tags.append(tag)\n",
    "                \n",
    "            elif e_tag.tag == 'c':\n",
    "                if e_tag.text is not None:\n",
    "                    tag = e_tag.attrib['c5']\n",
    "                    word = e_tag.text.replace(\" \", \"\")\n",
    "                    \n",
    "                    sentence.append(word)\n",
    "                    tags.append(tag)\n",
    "                    \n",
    "            elif e_tag.tag == 'mw':\n",
    "                tag = e_tag.attrib['c5']\n",
    "                word = \"\"\n",
    "                for w_tag in e_tag.iterfind('w'):     \n",
    "                    word += w_tag.text.replace(\" \", \"\")\n",
    "                \n",
    "                sentence.append(word)\n",
    "                tags.append(tag)\n",
    "                \n",
    "            elif e_tag.tag == 'hi':\n",
    "                \n",
    "                for w_tag in e_tag.iterfind('w'):     \n",
    "                    word = w_tag.text.replace(\" \", \"\")\n",
    "                    tag = w_tag.attrib['c5']\n",
    "                        \n",
    "                    sentence.append(word)\n",
    "                    tags.append(tag)\n",
    "                \n",
    "        data.append(sentence)\n",
    "        labels.append(tags)\n",
    "\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path):\n",
    "\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    for subdir, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "\n",
    "            fileName = subdir + '/' + str(file)\n",
    "            file_data, file_labels = parse_data(fileName)\n",
    "            data.extend(file_data)\n",
    "            labels.extend(file_labels)\n",
    "\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "\n",
    "train_path = 'Train-corpus/'\n",
    "test_path = 'Test-corpus/'\n",
    "\n",
    "data, labels = load_dataset(train_path)\n",
    "test_data, test_labels = load_dataset(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "483629\n",
      "483629\n",
      "['Wonder', 'boy', \"'s\", 'eyes', 'on', 'Wembley', '.']\n",
      "['VVB-NN1', 'NN1', 'POS', 'NN2', 'PRP', 'NP0', 'PUN']\n",
      "200468\n",
      "200468\n",
      "['These', '‘', 'communities', '’', 'are', 'of', 'two', 'kinds', '.']\n",
      "['DT0', 'PUQ', 'NN2', 'PUQ', 'VBB', 'PRF', 'CRD', 'NN2', 'PUN']\n"
     ]
    }
   ],
   "source": [
    "print(len(data))\n",
    "print(len(labels))\n",
    "\n",
    "print(data[0])\n",
    "print(labels[0])\n",
    "\n",
    "print(len(test_data))\n",
    "print(len(test_labels))\n",
    "\n",
    "print(test_data[11])\n",
    "print(test_labels[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "dkES1f_ROwPn"
   },
   "outputs": [],
   "source": [
    "# Load JSON Files\n",
    "\n",
    "with open('words.json') as f:\n",
    "    word_dict = json.load(f)\n",
    "with open('tags.json') as f:\n",
    "    tag_dict = json.load(f)\n",
    "with open('word_tags.json') as f:\n",
    "    word_tags_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "R6XVaCmZOwPs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n",
      "193511\n",
      "253488\n"
     ]
    }
   ],
   "source": [
    "print(len(tag_dict))\n",
    "print(len(word_dict))\n",
    "print(len(word_tags_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_word_tag_freq_matrix():\n",
    "    \n",
    "    rows = len(word_dict.keys())\n",
    "    cols = len(tag_dict.keys())\n",
    "    \n",
    "    mat = [[0 for i in range(cols)] for j in range(rows)] \n",
    "    \n",
    "    i=0\n",
    "    for word in word_dict.keys():\n",
    "        j=0\n",
    "        for tag in tag_dict.keys():\n",
    "            case = word + \"_\" + tag\n",
    "            if case in word_tags_dict.keys():\n",
    "                mat[i][j] = word_tags_dict[case]\n",
    "            j = j + 1\n",
    "        i = i + 1\n",
    "        \n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_matrix = compute_word_tag_freq_matrix()\n",
    "savetxt('freq_matrix.csv', freq_matrix, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_emission_prob_matrix(freq):\n",
    "    rows = len(freq_matrix)\n",
    "    cols = len(freq_matrix[0])\n",
    "    mat = freq\n",
    "    \n",
    "    for j in range(0, cols):\n",
    "        col_slice = list(get_column(mat, j))\n",
    "        total = sum(col_slice)\n",
    "        for i in range(rows):\n",
    "            mat[i][j] = mat[i][j]/total\n",
    "    \n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "emission_mat = compute_emission_prob_matrix(freq_matrix)\n",
    "savetxt('emission_mat.csv', emission_mat, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'VVB': 0, 'NN1': 1, 'POS': 2, 'NN2': 3, 'PRP': 4, 'NP0': 5, 'VVZ': 6, 'AT0': 7, 'PRF': 8, 'AJ0': 9, 'ORD': 10, 'DT0': 11, 'VM0': 12, 'VVI': 13, 'TO0': 14, 'VHI': 15, 'PNI': 16, 'VBZ': 17, 'XX0': 18, 'AV0': 19, 'CJC': 20, 'PNP': 21, 'PNQ': 22, 'DPS': 23, 'VHZ': 24, 'VVN': 25, 'NN0': 26, 'CJT': 27, 'CJS': 28, 'AVQ': 29, 'AVP': 30, 'DTQ': 31, 'AJS': 32, 'VHD': 33, 'CRD': 34, 'VVG': 35, 'VVD': 36, 'VBD': 37, 'VBG': 38, 'VBI': 39, 'AJC': 40, 'UNC': 41, 'VHB': 42, 'VBN': 43, 'PNX': 44, 'VHG': 45, 'EX0': 46, 'VBB': 47, 'VDN': 48, 'VDD': 49, 'ITJ': 50, 'ZZ0': 51, 'VHN': 52, 'VDB': 53, 'VDZ': 54, 'VDI': 55, 'VDG': 56, 'PUN': 57, 'PUQ': 58, 'PUL': 59, 'PUR': 60}\n"
     ]
    }
   ],
   "source": [
    "tags_index_dict = dict(zip(list(tag_dict.keys()),range(0, len(tag_dict.keys()))))\n",
    "word_index_dict = dict(zip(list(word_dict.keys()),range(0, len(word_dict.keys()))))\n",
    "tags_inv_dict = {v: k for k, v in tags_index_dict.items()}\n",
    "word_inv_dict = {v: k for k, v in word_index_dict.items()}\n",
    "print(tags_index_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index(tag, isPrev=True):\n",
    "    if tag == \"start\":\n",
    "        return [0]\n",
    "    if tag == \"end\":\n",
    "        return [len(tags_index_dict.keys())]\n",
    "    if \"-\" in tag:\n",
    "        a1 = tags_index_dict[tag[:3]]\n",
    "        a2 = tags_index_dict[tag[4:]]\n",
    "        return [a1, a2]\n",
    "    else:\n",
    "        a = tags_index_dict[tag]\n",
    "        return [a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tag_tag_frequency_matrix(data, labels):\n",
    "    \n",
    "    rows = len(tag_dict.keys()) + 1\n",
    "    cols = len(tag_dict.keys()) + 1\n",
    "    \n",
    "    mat = [[0 for i in range(cols)] for j in range(rows)] \n",
    "    \n",
    "    i=0\n",
    "    for sentence in data:\n",
    "        prev_tag = \"start\"\n",
    "        curr_tag = \"start\"\n",
    "        \n",
    "        j=0\n",
    "        for word in sentence:\n",
    "            prev_tag = curr_tag\n",
    "            curr_tag = labels[i][j]\n",
    "            \n",
    "            prev_index = get_index(prev_tag)\n",
    "            curr_index = get_index(curr_tag)\n",
    "            \n",
    "            a1=0\n",
    "            a2=0\n",
    "            b1=0\n",
    "            b2=0\n",
    "            \n",
    "            if len(prev_index) == 1:\n",
    "                a = prev_index[0]\n",
    "                if prev_tag != \"start\":\n",
    "                    a = a + 1\n",
    "                if len(curr_index) == 1:\n",
    "                    b = curr_index[0]\n",
    "                    mat[a][b] = mat[a][b] + 1\n",
    "                else:\n",
    "                    b1 = curr_index[0]\n",
    "                    b2 = curr_index[1]\n",
    "                    mat[a][b1] = mat[a][b1] + 1\n",
    "                    mat[a][b2] = mat[a][b2] + 1\n",
    "                    \n",
    "            else:\n",
    "                a1 = prev_index[0] + 1\n",
    "                a2 = prev_index[1] + 1\n",
    "                if len(curr_index) == 1:\n",
    "                    b = curr_index[0]\n",
    "                    mat[a1][b] = mat[a1][b] + 1\n",
    "                    mat[a2][b] = mat[a2][b] + 1\n",
    "                    \n",
    "                else:\n",
    "                    b1 = curr_index[0]\n",
    "                    b2 = curr_index[1]\n",
    "                    mat[a1][b1] = mat[a1][b1] + 1\n",
    "                    mat[a1][b2] = mat[a1][b2] + 1\n",
    "                    mat[a2][b1] = mat[a2][b1] + 1\n",
    "                    mat[a2][b2] = mat[a2][b2] + 1\n",
    "            \n",
    "            j=j+1\n",
    "            \n",
    "        curr_index = get_index(curr_tag)\n",
    "        \n",
    "        if len(curr_index) == 1:\n",
    "            b = curr_index[0] + 1\n",
    "            mat[b][61] = mat[b][61] + 1\n",
    "        else:\n",
    "            b1 = curr_index[0] + 1\n",
    "            b2 = curr_index[1] + 1\n",
    "            mat[b1][61] = mat[b1][61] + 1\n",
    "            mat[b2][61] = mat[b2][61] + 1\n",
    "            \n",
    "        i=i+1\n",
    "        \n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_tag_freq_matrix = compute_tag_tag_frequency_matrix(data, labels)\n",
    "savetxt('tag_tag_matrix.csv',tag_tag_freq_matrix, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_transition_prob_matrix(freq):\n",
    "    rows = len(freq)\n",
    "    cols = len(freq[0])\n",
    "    \n",
    "    mat = np.array(freq, dtype=float)\n",
    "    \n",
    "    for i in range(0, rows):\n",
    "        \n",
    "        total = float(sum(mat[i]))\n",
    "        if total == 0:\n",
    "            total = 1\n",
    "            \n",
    "        mat[i] = [x/total for x in mat[i]]\n",
    "            \n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_mat = compute_transition_prob_matrix(tag_tag_freq_matrix)\n",
    "savetxt('transition_matrix.csv', transition_mat, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_tags = {}\n",
    "count = 0\n",
    "\n",
    "def compute_possible_combinations(data, labels):\n",
    "    \n",
    "    for i, sentence in enumerate(data):\n",
    "        for j, word in enumerate(sentence):\n",
    "            label = labels[i][j]\n",
    "            \n",
    "            if \"-\" in label:\n",
    "                l1 = label[:3]\n",
    "                l2 = label[4:]\n",
    "                try:\n",
    "                    if l1 not in possible_tags[word]:\n",
    "                        possible_tags[word].append(l1)\n",
    "                    if l2 not in possible_tags[word]:\n",
    "                        possible_tags[word].append(l2)\n",
    "                except:\n",
    "                    init = []\n",
    "                    init.append(l1)\n",
    "                    init.append(l2)\n",
    "                    possible_tags[word] = init\n",
    "            else:\n",
    "                try:\n",
    "                    if label not in possible_tags[word]:\n",
    "                        possible_tags[word].append(label)\n",
    "                except:\n",
    "                    init = []\n",
    "                    init.append(label)\n",
    "                    possible_tags[word] = init\n",
    "            \n",
    "compute_possible_combinations(data, labels)\n",
    "compute_possible_combinations(test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Laplace Smoothing\n",
    "def probability_word_given_tag(word, tag):\n",
    "    \n",
    "    count_tag = tag_dict[tag]\n",
    "    \n",
    "    if word+'_'+tag in word_tags_dict.keys():\n",
    "        count_word_tag = word_tags_dict[word+'_'+tag]\n",
    "\n",
    "        return (count_word_tag)/(count_tag)\n",
    "    \n",
    "    else:\n",
    "        return 1/(count_tag + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Viterbi(sentence):\n",
    "    predicted = []\n",
    "    cache = {}\n",
    "    for index, word in enumerate(sentence):\n",
    "        if index == 0:\n",
    "            cache[index] = {}\n",
    "            tags = possible_tags[word]\n",
    "            for tag in tags:\n",
    "\n",
    "                if word in word_dict.keys():\n",
    "                    word_index = word_index_dict[word]\n",
    "                    tag_index = tags_index_dict[tag]\n",
    "\n",
    "                    cache[index][tag] = ['##', transition_mat[0][tag_index] * emission_mat[word_index][tag_index]]\n",
    "\n",
    "                else:\n",
    "                    tag_index = tags_index_dict[tag]\n",
    "                    cache[index][tag] = ['##', transition_mat[0][tag_index] * probability_word_given_tag(word, tag)]\n",
    "\n",
    "        else:\n",
    "            cache[index] = {}\n",
    "            prev_states = list(cache[index-1].keys())\n",
    "\n",
    "            tags = possible_tags[word]\n",
    "            for tag in tags:\n",
    "                temp = []\n",
    "                for prev_state in prev_states:\n",
    "                    case = word + \"_\" + tag\n",
    "                            \n",
    "                    if word in word_dict.keys():\n",
    "                        word_index = word_index_dict[word]\n",
    "                        curr_index = tags_index_dict[tag]\n",
    "                        prev_index = tags_index_dict[prev_state]+1\n",
    "\n",
    "                        temp.append(cache[index-1][prev_state][1] * transition_mat[prev_index][curr_index] * emission_mat[word_index][curr_index])\n",
    "                    else:\n",
    "                        curr_index = tags_index_dict[tag]\n",
    "                        prev_index = tags_index_dict[prev_state]+1\n",
    "                        temp.append(cache[index-1][prev_state][1] * transition_mat[prev_index][curr_index] * probability_word_given_tag(word, tag))\n",
    "                        \n",
    "                max_temp_index = temp.index(max(temp))\n",
    "                best_prev_tag = prev_states[max_temp_index]\n",
    "                cache[index][tag] = [best_prev_tag, max(temp)]\n",
    "    \n",
    "    index = len(sentence)\n",
    "    cache[index] = {}\n",
    "    prev_states = list(cache[index-1].keys())\n",
    "    \n",
    "    temp = []\n",
    "    for prev_state in prev_states:\n",
    "\n",
    "        curr_index = 61\n",
    "        prev_index = tags_index_dict[prev_state] + 1\n",
    "\n",
    "        temp.append(cache[index-1][prev_state][1] * transition_mat[prev_index][curr_index])   \n",
    "\n",
    "    max_temp_index = temp.index(max(temp))\n",
    "    best_prev_tag = prev_states[max_temp_index]\n",
    "    cache[index]['&&'] = [best_prev_tag, max(temp)]\n",
    "\n",
    "    # Backtracing to extract the best possible tags for the \n",
    "    pred_tags = []\n",
    "    all_word_index = cache.keys()\n",
    "    last_word_index = max(all_word_index)\n",
    "    \n",
    "    for index in range(len(all_word_index)):\n",
    "        \n",
    "        word_index = last_word_index - index\n",
    "        \n",
    "        if word_index == last_word_index:\n",
    "            pred_tags.append(cache[word_index]['&&'][0])\n",
    "            \n",
    "        if word_index < last_word_index and word_index > 0:\n",
    "            pred_tags.append(cache[word_index][pred_tags[len(pred_tags)-1]][0])\n",
    "            \n",
    "    predicted.append(list(reversed(pred_tags)))\n",
    "\n",
    "    return predicted[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DT0', 'PUQ', 'NN2', 'PUQ', 'VBB', 'PRF', 'CRD', 'NN2', 'PUN']\n",
      "['AJ0', 'NN1', 'NN1', 'PRP', 'CRD', 'NN1', 'PUL', 'NN0', 'PUR', 'NN2', 'PUN']\n"
     ]
    }
   ],
   "source": [
    "print(Viterbi(['These', '‘', 'communities', '’', 'are', 'of', 'two', 'kinds', '.']))\n",
    "print(Viterbi(['Average', 'foot', 'position', 'for', '11', 'stone', '(', '70kg', ')', 'sailors', '.']))\n",
    "\n",
    "# ['DT0', 'PUQ', 'NN2', 'PUQ', 'VBB', 'PRF', 'CRD', 'NN2', 'PUN']\n",
    "# ['AJ0', 'NN1', 'NN1', 'PRP', 'CRD', 'NN1', 'PUL', 'NN0', 'PUR', 'NN2', 'PUN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(data):\n",
    "    pred = []\n",
    "    for index, sentence in enumerate(data):\n",
    "        if len(sentence) != 0:\n",
    "            pred.append(Viterbi(sentence))\n",
    "        else:\n",
    "            pred.append([])\n",
    "        if ((index+1) % 10000==0):\n",
    "            print(\"Predicted: %d \" % (index+1))  \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 10000 \n",
      "Predicted: 20000 \n",
      "Predicted: 30000 \n",
      "Predicted: 40000 \n",
      "Predicted: 50000 \n",
      "Predicted: 60000 \n",
      "Predicted: 70000 \n",
      "Predicted: 80000 \n",
      "Predicted: 90000 \n",
      "Predicted: 100000 \n",
      "Predicted: 110000 \n",
      "Predicted: 120000 \n",
      "Predicted: 130000 \n",
      "Predicted: 140000 \n",
      "Predicted: 150000 \n",
      "Predicted: 160000 \n",
      "Predicted: 170000 \n",
      "Predicted: 180000 \n",
      "Predicted: 190000 \n",
      "Predicted: 200000 \n"
     ]
    }
   ],
   "source": [
    "preds = get_predictions(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(test_data, test_labels, preds):\n",
    "    \n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    \n",
    "    print(\"Total: %d\" % len(test_data))\n",
    "    \n",
    "    t0 = time.process_time()\n",
    "    \n",
    "    for index, pred_labels in enumerate(preds):\n",
    "        true_labels = test_labels[index]\n",
    "        \n",
    "        for i, pred_label in enumerate(pred_labels):\n",
    "            if pred_label in true_labels[i]:\n",
    "                correct = correct + 1\n",
    "            else:\n",
    "                incorrect = incorrect + 1\n",
    "                \n",
    "    print(\"Evaluated Words: %d \" % (incorrect + correct))   \n",
    "    print(\"Correct: %d \" % (correct))   \n",
    "    print(\"Incorrect: %d \" % (incorrect))   \n",
    "    print(\"Time Taken: %.2f \\n \" % (time.process_time()-t0))\n",
    "    \n",
    "    print(\"Final Accuracy = %.06f\"  % (correct/(correct+incorrect)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 200468\n",
      "Evaluated Words: 4092252 \n",
      "Correct: 4013448 \n",
      "Incorrect: 78804 \n",
      "Time Taken: 0.64 \n",
      " \n",
      "Final Accuracy = 0.980743\n"
     ]
    }
   ],
   "source": [
    "get_accuracy(test_data, test_labels, preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
