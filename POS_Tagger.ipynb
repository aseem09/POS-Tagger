{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "POS-Tagger.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDj9hEazOwOe"
      },
      "source": [
        "from reader import parse_data, list_to_freq_dict, parse_data_test\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import pprint\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import multiprocessing\n",
        "import time\n",
        "\n",
        "pp = pprint.PrettyPrinter(indent=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d61HzncGOwO4"
      },
      "source": [
        "def load_dataset(path, training=True):\n",
        "\n",
        "    if training == True:\n",
        "        word_list = []\n",
        "        tag_list = []\n",
        "        word_tags_list = []\n",
        "        \n",
        "        for subdir, dirs, files in os.walk(path):\n",
        "            for file in files:\n",
        "\n",
        "                fileName = subdir + '/' + str(file)\n",
        "                words, tags, word_tags = parse_data(fileName)\n",
        "\n",
        "                word_list.extend(words)\n",
        "                tag_list.extend(tags)\n",
        "                word_tags_list.extend(word_tags)\n",
        "            \n",
        "        return word_list, tag_list, word_tags_list\n",
        "        \n",
        "    else:\n",
        "        all_tuples = []\n",
        "        \n",
        "        for subdir, dirs, files in os.walk(path):\n",
        "            for file in files:\n",
        "\n",
        "                fileName = subdir + '/' + str(file)\n",
        "                tuples = parse_data_test(fileName)\n",
        "                all_tuples.extend(tuples)\n",
        "\n",
        "        return all_tuples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4RHCG32OwO_"
      },
      "source": [
        "# Load Dataset\n",
        "\n",
        "train_path = 'Train-corpus/'\n",
        "test_path = 'Test-corpus/'\n",
        "\n",
        "# word_list, tag_list, word_tags_list = load_dataset(train_path)\n",
        "test_tuples = load_dataset(test_path, training=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbCt3FrSOwPH"
      },
      "source": [
        "# Generate Frequency Dict for words\n",
        "\n",
        "word_dict = list_to_freq_dict(word_list)\n",
        "\n",
        "with open('words.json', 'w') as outfile:\n",
        "    json.dump(word_dict, outfile, indent=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svtJIHB1OwPM"
      },
      "source": [
        "# Print top 10 words\n",
        "\n",
        "k1 = Counter(word_dict)\n",
        "top_words = k1.most_common(10)\n",
        "print('Top 10 Words are: ')\n",
        "for i in top_words:\n",
        "    print(i[0], \" :\", i[1], \" \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9KDCcnfOwPR"
      },
      "source": [
        "# Plot Top 10 Words\n",
        "\n",
        "keys, values = [i[0] for i in top_words], [i[1] for i in top_words]\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "ax.bar(keys,values)\n",
        "plt.show()\n",
        "\n",
        "patches, texts = plt.pie(values, labels=keys)\n",
        "plt.legend(patches, keys, loc=\"best\")\n",
        "plt.savefig('words_chart.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Gl-4CVoOwPX"
      },
      "source": [
        "# Generate Frequency Dict for tags\n",
        "\n",
        "tag_dict = list_to_freq_dict(tag_list)\n",
        "with open('tags.json', 'w') as outfile:\n",
        "    json.dump(tag_dict, outfile, indent=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wq-wlnoOwPb"
      },
      "source": [
        "# Print Top 10 Tags\n",
        "\n",
        "k1 = Counter(tag_dict)\n",
        "top_tags = k1.most_common(10)\n",
        "print('Top 10 Tags are: ')\n",
        "for i in top_tags:\n",
        "    print(i[0], \" :\", i[1], \" \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_82e3ZnOwPf"
      },
      "source": [
        "# Plot Top 10 Tags\n",
        "\n",
        "keys, values = [i[0] for i in top_tags], [i[1] for i in top_tags]\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "ax.bar(keys,values)\n",
        "plt.show()\n",
        "\n",
        "patches, texts = plt.pie(values, labels=keys)\n",
        "plt.legend(patches, keys, loc=\"best\")\n",
        "plt.savefig('tags_chart.png')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37JGfbt4OwPj"
      },
      "source": [
        "# Generate Frequency Dict for word_tags\n",
        "\n",
        "word_tags_dict = list_to_freq_dict(word_tags_list)\n",
        "with open('word_tags.json', 'w') as outfile:\n",
        "    json.dump(word_tags_dict, outfile, indent=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkES1f_ROwPn"
      },
      "source": [
        "# Load JSON Files\n",
        "\n",
        "with open('words.json') as f:\n",
        "    word_dict = json.load(f)\n",
        "with open('tags.json') as f:\n",
        "    tag_dict = json.load(f)\n",
        "with open('word_tags.json') as f:\n",
        "    word_tags_dict = json.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6XVaCmZOwPs"
      },
      "source": [
        "print(len(tag_dict))\n",
        "print(len(word_dict))\n",
        "print(len(word_tags_dict))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUiy1SUuOwPw"
      },
      "source": [
        "# Use Laplace Smoothing\n",
        "def probability_word_given_tag(word, tag):\n",
        "    \n",
        "    count_tag = tag_dict[tag]\n",
        "    \n",
        "    if word+'_'+tag in word_tags_dict.keys():\n",
        "        count_word_tag = word_tags_dict[word+'_'+tag]\n",
        "\n",
        "        return (count_word_tag)/(count_tag)\n",
        "    \n",
        "    else:\n",
        "        return 1/(count_tag + 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69H2aShNOwPz",
        "outputId": "c8736a81-ba0a-4cbb-d5af-da21724fd125"
      },
      "source": [
        "print(probability_word_given_tag('a','AT0'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.23395366546859694\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWnaks2hOwP6"
      },
      "source": [
        "def best_tag_for_word(word):\n",
        "    max_prob = 0\n",
        "    most_prob_tag = 'none'\n",
        "    for tag in tag_dict.keys():\n",
        "        p_word_tag = probability_word_given_tag(word,tag)\n",
        "        p_tag = tag_dict[tag]\n",
        "        \n",
        "        p_tag_word = (p_word_tag*p_tag)\n",
        "        \n",
        "        if max_prob < p_tag_word:\n",
        "            max_prob = p_tag_word\n",
        "            most_prob_tag = tag\n",
        "    \n",
        "    return most_prob_tag"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRGvBbCxOwP8"
      },
      "source": [
        "def create_model():\n",
        "    model = {}\n",
        "    for word in word_dict.keys():\n",
        "        model[word] = best_tag_for_word(word)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HPBQi44OwQA"
      },
      "source": [
        "model = create_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HC-NX6gxOwQE"
      },
      "source": [
        "print(model['of'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnoXJnQfOwQH"
      },
      "source": [
        "print(len(test_tuples))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrXbeOeYOwQK"
      },
      "source": [
        "def check_prediction(word_tuple):\n",
        "    \n",
        "    word, label = word_tuple\n",
        "    logit = best_tag_for_word(word)\n",
        "    if logit in label:\n",
        "        return True\n",
        "    else:\n",
        "        return False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afbkH-cQOwQM"
      },
      "source": [
        "def get_model_accuracy(test_tuples):\n",
        "    \n",
        "    correct = 0\n",
        "    incorrect = 0\n",
        "    \n",
        "    err = 0\n",
        "    \n",
        "    print(\"Total: %d\" % len(test_tuples))\n",
        "    \n",
        "    t0 = time.process_time()\n",
        "    \n",
        "    for i in range(0,len(test_tuples)):\n",
        "        \n",
        "        word, label = test_tuples[i]\n",
        "        \n",
        "        if word in model.keys():\n",
        "            if model[word] in label:\n",
        "                correct = correct + 1\n",
        "            else:\n",
        "                incorrect = incorrect + 1\n",
        "        \n",
        "        else:\n",
        "            err = err + 1\n",
        "            if best_tag_for_word(word) in label:\n",
        "                correct = correct + 1\n",
        "            else:\n",
        "                incorrect = incorrect + 1\n",
        "                \n",
        "        \n",
        "    print(\"Evaluated: %d \" % (incorrect + correct))    \n",
        "    print(\"Time Taken: %.2f \\n \" % (time.process_time()-t0))\n",
        "    \n",
        "    print(\"Final Accuracy = %.06f\"  % (correct/(correct+incorrect)))\n",
        "    print(\"Errors: %d \" % err)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRJ6j2wwOwQR",
        "outputId": "e9a9c3de-b95f-4035-8846-bb51a7b15f37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "get_model_accuracy(test_tuples)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total: 3630025\n",
            "Evaluated: 3630025 \n",
            "Time Taken: 2.78 \n",
            " \n",
            "Final Accuracy = 0.912357\n",
            "Errors: 65350 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKZ5CK3SOwQU"
      },
      "source": [
        "from sklearn import metrics\n",
        "import seaborn as sn\n",
        "tags = list(tag_dict.keys())\n",
        "def get_confusion_matrix(test_tuples):\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    for i in range(0,len(test_tuples)):\n",
        "        word, label = test_tuples[i]\n",
        "        y_true.append(label)\n",
        "        if word in model.keys():\n",
        "            y_pred.append(model[word])\n",
        "        else:\n",
        "            y_pred.append(best_tag_for_word(word))\n",
        "    plt.figure(figsize=(25, 22), dpi=600)\n",
        "    df_cm = pd.DataFrame(metrics.confusion_matrix(y_true, y_pred, tags), range(len(tags)), range(len(tags)))\n",
        "    sn.set(font_scale=1.0)\n",
        "    sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 5}) # font size\n",
        "    # plt.show()\n",
        "    # plt.savefig('confusion_matrix.png')\n",
        "    plt.savefig('cm.svg', format='svg', dpi=1200)\n",
        "    # print(metrics.confusion_matrix(y_true, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0N_L59hOwQY",
        "outputId": "d1b007b8-a759-4255-956d-65617dfe52c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "get_confusion_matrix   (test_tuples)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/home/arnesh07/venvs/aivenv/lib/python3.6/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass labels=['VBB', 'DPS', 'VDG', 'VBG', 'VBD', 'VBI', 'VDZ', 'AV0', 'VBN', 'VDB', 'VHI', 'VDD', 'CRD', 'VHD', 'VDI', 'VBZ', 'DTQ', 'VDN', 'NP0', 'VM0', 'VHB', 'PRF', 'VVZ', 'AJ0', 'VHZ', 'POS', 'VVN', 'PRP', 'VVI', 'VVG', 'VVD', 'VVB', 'XX0', 'EX0', 'CJC', 'AJS', 'VHG', 'ZZ0', 'UNC', 'CJS', 'AJC', 'NN2', 'CJT', 'NN0', 'PNX', 'ITJ', 'PNQ', 'PNP', 'TO0', 'AVP', 'AVQ', 'PNI', 'VHN', 'AT0', 'ORD', 'DT0', 'NN1'] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdaxLDcqOwQb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_IFYBSOOwQf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}