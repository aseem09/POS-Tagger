{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2Sbq6xDXIj0T"
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import pickle\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "import time\n",
    "from sklearn import metrics\n",
    "import seaborn as sn\n",
    "from numpy import asarray\n",
    "from numpy import savetxt\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "-LzLsddKIj0U"
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "def get_column(list_, n):\n",
    "    return map(operator.itemgetter(n), list_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "rm9MeicGIj0U"
   },
   "outputs": [],
   "source": [
    "def parse_data(file):\n",
    "    \n",
    "    tree = ET.parse(file)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    data = []\n",
    "    labels = []\n",
    "    \n",
    "    for s_tag in root.iter('s'):\n",
    "        \n",
    "        sentence = []\n",
    "        tags = []\n",
    "        \n",
    "        for e_tag in s_tag:\n",
    "                \n",
    "            if e_tag.tag == 'w' or e_tag.tag == 'c':\n",
    "                if e_tag.text is not None:\n",
    "                    tag = e_tag.attrib['c5']\n",
    "                    word = e_tag.text.replace(\" \", \"\")\n",
    "                    \n",
    "                    sentence.append(word)\n",
    "                    tags.append(tag)\n",
    "                    \n",
    "            elif e_tag.tag == 'mw':\n",
    "                tag = e_tag.attrib['c5']\n",
    "                word = \"\"\n",
    "                for w_tag in e_tag.iterfind('w'):     \n",
    "                    word += w_tag.text.replace(\" \", \"\")\n",
    "                \n",
    "                sentence.append(word)\n",
    "                tags.append(tag)\n",
    "                \n",
    "            elif e_tag.tag == 'hi' or e_tag.tag == 'corr':\n",
    "                \n",
    "                for r_tag in e_tag:\n",
    "                \n",
    "                    if r_tag.tag == 'w' or r_tag.tag == 'c':\n",
    "                        if r_tag.text is not None:\n",
    "                            tag = r_tag.attrib['c5']\n",
    "                            word = r_tag.text.replace(\" \", \"\")\n",
    "\n",
    "                            sentence.append(word)\n",
    "                            tags.append(tag)\n",
    "\n",
    "                    elif r_tag.tag == 'mw':\n",
    "                        tag = r_tag.attrib['c5']\n",
    "                        word = \"\"\n",
    "                        for w_tag in r_tag.iterfind('w'):     \n",
    "                            word += w_tag.text.replace(\" \", \"\")\n",
    "\n",
    "                        sentence.append(word)\n",
    "                        tags.append(tag)\n",
    "                \n",
    "        data.append(sentence)\n",
    "        labels.append(tags)\n",
    "\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "5QpNALZSIj0U"
   },
   "outputs": [],
   "source": [
    "def load_dataset(path):\n",
    "\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    for subdir, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "\n",
    "            fileName = subdir + '/' + str(file)\n",
    "            file_data, file_labels = parse_data(fileName)\n",
    "            data.extend(file_data)\n",
    "            labels.extend(file_labels)\n",
    "\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "lfD563pVIj0U"
   },
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "\n",
    "train_path = 'Train-corpus/'\n",
    "test_path = 'Test-corpus/'\n",
    "\n",
    "data, labels = load_dataset(train_path)\n",
    "test_data, test_labels = load_dataset(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "utQnqd6EIj0U",
    "outputId": "4d0faee0-87c6-44c8-fc9e-ab8ef8803687",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "483629\n",
      "483629\n",
      "['Wonder', 'boy', \"'s\", 'eyes', 'on', 'Wembley', '.']\n",
      "['VVB-NN1', 'NN1', 'POS', 'NN2', 'PRP', 'NP0', 'PUN']\n",
      "200468\n",
      "200468\n",
      "['These', '‘', 'communities', '’', 'are', 'of', 'two', 'kinds', '.']\n",
      "['DT0', 'PUQ', 'NN2', 'PUQ', 'VBB', 'PRF', 'CRD', 'NN2', 'PUN']\n"
     ]
    }
   ],
   "source": [
    "print(len(data))\n",
    "print(len(labels))\n",
    "\n",
    "print(data[0])\n",
    "print(labels[0])\n",
    "\n",
    "print(len(test_data))\n",
    "print(len(test_labels))\n",
    "\n",
    "print(test_data[11])\n",
    "print(test_labels[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "dkES1f_ROwPn"
   },
   "outputs": [],
   "source": [
    "# Load JSON Files\n",
    "\n",
    "with open('words.json') as f:\n",
    "    word_dict = json.load(f)\n",
    "with open('tags.json') as f:\n",
    "    tag_dict = json.load(f)\n",
    "with open('word_tags.json') as f:\n",
    "    word_tags_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R6XVaCmZOwPs",
    "outputId": "9c487106-7292-462d-affc-12c5ae84266d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n",
      "193511\n",
      "253488\n"
     ]
    }
   ],
   "source": [
    "print(len(tag_dict))\n",
    "print(len(word_dict))\n",
    "print(len(word_tags_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Lwq6kxsqIj0V"
   },
   "outputs": [],
   "source": [
    "def compute_word_tag_freq_matrix():\n",
    "    \n",
    "    rows = len(word_dict.keys())\n",
    "    cols = len(tag_dict.keys())\n",
    "    \n",
    "    mat = [[0 for i in range(cols)] for j in range(rows)] \n",
    "    \n",
    "    i=0\n",
    "    for word in word_dict.keys():\n",
    "        j=0\n",
    "        for tag in tag_dict.keys():\n",
    "            case = word + \"_\" + tag\n",
    "            if case in word_tags_dict.keys():\n",
    "                mat[i][j] = word_tags_dict[case]\n",
    "            j = j + 1\n",
    "        i = i + 1\n",
    "        \n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "fTZCbh_dIj0V"
   },
   "outputs": [],
   "source": [
    "freq_matrix = compute_word_tag_freq_matrix()\n",
    "savetxt('freq_matrix.csv', freq_matrix, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "8CqThn1vIj0W"
   },
   "outputs": [],
   "source": [
    "def compute_emission_prob_matrix(freq):\n",
    "    rows = len(freq_matrix)\n",
    "    cols = len(freq_matrix[0])\n",
    "    mat = freq\n",
    "    \n",
    "    for j in range(0, cols):\n",
    "        col_slice = list(get_column(mat, j))\n",
    "        total = sum(col_slice)\n",
    "        for i in range(rows):\n",
    "            mat[i][j] = mat[i][j]/total\n",
    "    \n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "VSlaZA_xIj0X"
   },
   "outputs": [],
   "source": [
    "emission_mat = compute_emission_prob_matrix(freq_matrix)\n",
    "savetxt('emission_mat.csv', emission_mat, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "66SH1AP2Ij0X",
    "outputId": "167a7cbf-df0a-4546-bd05-d5e774eedfb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'VVB': 0, 'NN1': 1, 'POS': 2, 'NN2': 3, 'PRP': 4, 'NP0': 5, 'VVZ': 6, 'AT0': 7, 'PRF': 8, 'AJ0': 9, 'ORD': 10, 'DT0': 11, 'VM0': 12, 'VVI': 13, 'TO0': 14, 'VHI': 15, 'PNI': 16, 'VBZ': 17, 'XX0': 18, 'AV0': 19, 'CJC': 20, 'PNP': 21, 'PNQ': 22, 'DPS': 23, 'VHZ': 24, 'VVN': 25, 'NN0': 26, 'CJT': 27, 'CJS': 28, 'AVQ': 29, 'AVP': 30, 'DTQ': 31, 'AJS': 32, 'VHD': 33, 'CRD': 34, 'VVG': 35, 'VVD': 36, 'VBD': 37, 'VBG': 38, 'VBI': 39, 'AJC': 40, 'UNC': 41, 'VHB': 42, 'VBN': 43, 'PNX': 44, 'VHG': 45, 'EX0': 46, 'VBB': 47, 'VDN': 48, 'VDD': 49, 'ITJ': 50, 'ZZ0': 51, 'VHN': 52, 'VDB': 53, 'VDZ': 54, 'VDI': 55, 'VDG': 56, 'PUN': 57, 'PUQ': 58, 'PUL': 59, 'PUR': 60}\n"
     ]
    }
   ],
   "source": [
    "tags_index_dict = dict(zip(list(tag_dict.keys()),range(0, len(tag_dict.keys()))))\n",
    "word_index_dict = dict(zip(list(word_dict.keys()),range(0, len(word_dict.keys()))))\n",
    "tags_inv_dict = {v: k for k, v in tags_index_dict.items()}\n",
    "word_inv_dict = {v: k for k, v in word_index_dict.items()}\n",
    "print(tags_index_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "EtZkdB-gIj0X"
   },
   "outputs": [],
   "source": [
    "def get_index(tag, isPrev=True):\n",
    "    if tag == \"start\":\n",
    "        return [0]\n",
    "    if tag == \"end\":\n",
    "        return [len(tags_index_dict.keys())]\n",
    "    if \"-\" in tag:\n",
    "        a1 = tags_index_dict[tag[:3]]\n",
    "        a2 = tags_index_dict[tag[4:]]\n",
    "        return [a1, a2]\n",
    "    else:\n",
    "        a = tags_index_dict[tag]\n",
    "        return [a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "rEEzgXwHIj0X"
   },
   "outputs": [],
   "source": [
    "def compute_tag_tag_frequency_matrix(data, labels):\n",
    "    \n",
    "    rows = len(tag_dict.keys()) + 1\n",
    "    cols = len(tag_dict.keys()) + 1\n",
    "    \n",
    "    mat = [[0 for i in range(cols)] for j in range(rows)] \n",
    "    \n",
    "    i=0\n",
    "    for sentence in data:\n",
    "        prev_tag = \"start\"\n",
    "        curr_tag = \"start\"\n",
    "        \n",
    "        j=0\n",
    "        for word in sentence:\n",
    "            prev_tag = curr_tag\n",
    "            curr_tag = labels[i][j]\n",
    "            \n",
    "            prev_index = get_index(prev_tag)\n",
    "            curr_index = get_index(curr_tag)\n",
    "            \n",
    "            a1=0\n",
    "            a2=0\n",
    "            b1=0\n",
    "            b2=0\n",
    "            \n",
    "            if len(prev_index) == 1:\n",
    "                a = prev_index[0]\n",
    "                if prev_tag != \"start\":\n",
    "                    a = a + 1\n",
    "                if len(curr_index) == 1:\n",
    "                    b = curr_index[0]\n",
    "                    mat[a][b] = mat[a][b] + 1\n",
    "                else:\n",
    "                    b1 = curr_index[0]\n",
    "                    b2 = curr_index[1]\n",
    "                    mat[a][b1] = mat[a][b1] + 1\n",
    "                    mat[a][b2] = mat[a][b2] + 1\n",
    "                    \n",
    "            else:\n",
    "                a1 = prev_index[0] + 1\n",
    "                a2 = prev_index[1] + 1\n",
    "                if len(curr_index) == 1:\n",
    "                    b = curr_index[0]\n",
    "                    mat[a1][b] = mat[a1][b] + 1\n",
    "                    mat[a2][b] = mat[a2][b] + 1\n",
    "                    \n",
    "                else:\n",
    "                    b1 = curr_index[0]\n",
    "                    b2 = curr_index[1]\n",
    "                    mat[a1][b1] = mat[a1][b1] + 1\n",
    "                    mat[a1][b2] = mat[a1][b2] + 1\n",
    "                    mat[a2][b1] = mat[a2][b1] + 1\n",
    "                    mat[a2][b2] = mat[a2][b2] + 1\n",
    "            \n",
    "            j=j+1\n",
    "            \n",
    "        curr_index = get_index(curr_tag)\n",
    "        \n",
    "        if len(curr_index) == 1:\n",
    "            b = curr_index[0] + 1\n",
    "            mat[b][61] = mat[b][61] + 1\n",
    "        else:\n",
    "            b1 = curr_index[0] + 1\n",
    "            b2 = curr_index[1] + 1\n",
    "            mat[b1][61] = mat[b1][61] + 1\n",
    "            mat[b2][61] = mat[b2][61] + 1\n",
    "            \n",
    "        i=i+1\n",
    "        \n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "zWhRt0OhIj0X"
   },
   "outputs": [],
   "source": [
    "tag_tag_freq_matrix = compute_tag_tag_frequency_matrix(data, labels)\n",
    "savetxt('tag_tag_matrix.csv',tag_tag_freq_matrix, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "R2HWnRauIj0X"
   },
   "outputs": [],
   "source": [
    "def compute_transition_prob_matrix(freq):\n",
    "    rows = len(freq)\n",
    "    cols = len(freq[0])\n",
    "    \n",
    "    mat = np.array(freq, dtype=float)\n",
    "    \n",
    "    for i in range(0, rows):\n",
    "        \n",
    "        total = float(sum(mat[i]))\n",
    "        if total == 0:\n",
    "            total = 1\n",
    "            \n",
    "        mat[i] = [x/total for x in mat[i]]\n",
    "            \n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "shjbRkjkIj0X"
   },
   "outputs": [],
   "source": [
    "transition_mat = compute_transition_prob_matrix(tag_tag_freq_matrix)\n",
    "savetxt('transition_matrix.csv', transition_mat, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "i1ccMioeIj0X"
   },
   "outputs": [],
   "source": [
    "possible_tags = {}\n",
    "count = 0\n",
    "\n",
    "def compute_possible_combinations(data, labels):\n",
    "    \n",
    "    for i, sentence in enumerate(data):\n",
    "        for j, word in enumerate(sentence):\n",
    "            label = labels[i][j]\n",
    "            \n",
    "            if \"-\" in label:\n",
    "                l1 = label[:3]\n",
    "                l2 = label[4:]\n",
    "                try:\n",
    "                    if l1 not in possible_tags[word]:\n",
    "                        possible_tags[word].append(l1)\n",
    "                    if l2 not in possible_tags[word]:\n",
    "                        possible_tags[word].append(l2)\n",
    "                except:\n",
    "                    init = []\n",
    "                    init.append(l1)\n",
    "                    init.append(l2)\n",
    "                    possible_tags[word] = init\n",
    "            else:\n",
    "                try:\n",
    "                    if label not in possible_tags[word]:\n",
    "                        possible_tags[word].append(label)\n",
    "                except:\n",
    "                    init = []\n",
    "                    init.append(label)\n",
    "                    possible_tags[word] = init\n",
    "            \n",
    "compute_possible_combinations(data, labels)\n",
    "compute_possible_combinations(test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "p0ZEeFF3Ij0X"
   },
   "outputs": [],
   "source": [
    "# Use Laplace Smoothing\n",
    "def probability_word_given_tag(word, tag):\n",
    "    \n",
    "    count_tag = tag_dict[tag]\n",
    "    \n",
    "    if word+'_'+tag in word_tags_dict.keys():\n",
    "        count_word_tag = word_tags_dict[word+'_'+tag]\n",
    "\n",
    "        return (count_word_tag)/(count_tag)\n",
    "    \n",
    "    else:\n",
    "        return 1/(count_tag + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "QPdLC9XpIj0X"
   },
   "outputs": [],
   "source": [
    "def Viterbi(sentence):\n",
    "    predicted = []\n",
    "    cache = {}\n",
    "    for index, word in enumerate(sentence):\n",
    "        if index == 0:\n",
    "            cache[index] = {}\n",
    "            tags = possible_tags[word]\n",
    "            for tag in tags:\n",
    "\n",
    "                if word in word_dict.keys():\n",
    "                    word_index = word_index_dict[word]\n",
    "                    tag_index = tags_index_dict[tag]\n",
    "\n",
    "                    cache[index][tag] = ['##', transition_mat[0][tag_index] * emission_mat[word_index][tag_index]]\n",
    "\n",
    "                else:\n",
    "                    tag_index = tags_index_dict[tag]\n",
    "                    cache[index][tag] = ['##', transition_mat[0][tag_index] * probability_word_given_tag(word, tag)]\n",
    "\n",
    "        else:\n",
    "            cache[index] = {}\n",
    "            prev_states = list(cache[index-1].keys())\n",
    "            \n",
    "            tags = possible_tags[word]\n",
    "            for tag in tags:\n",
    "                temp = []\n",
    "                for prev_state in prev_states:\n",
    "                    case = word + \"_\" + tag\n",
    "                            \n",
    "                    if word in word_dict.keys():\n",
    "                        word_index = word_index_dict[word]\n",
    "                        curr_index = tags_index_dict[tag]\n",
    "                        prev_index = tags_index_dict[prev_state]+1\n",
    "\n",
    "                        temp.append(cache[index-1][prev_state][1] * transition_mat[prev_index][curr_index] * emission_mat[word_index][curr_index])\n",
    "                    else:\n",
    "                        curr_index = tags_index_dict[tag]\n",
    "                        prev_index = tags_index_dict[prev_state]+1\n",
    "                        temp.append(cache[index-1][prev_state][1] * transition_mat[prev_index][curr_index] * probability_word_given_tag(word, tag))\n",
    "                        \n",
    "                max_temp_index = temp.index(max(temp))\n",
    "                best_prev_tag = prev_states[max_temp_index]\n",
    "                cache[index][tag] = [best_prev_tag, max(temp)]\n",
    "    \n",
    "    index = len(sentence)\n",
    "    cache[index] = {}\n",
    "    prev_states = list(cache[index-1].keys())\n",
    "    \n",
    "    temp = []\n",
    "    for prev_state in prev_states:\n",
    "\n",
    "        curr_index = 61\n",
    "        prev_index = tags_index_dict[prev_state] + 1\n",
    "\n",
    "        temp.append(cache[index-1][prev_state][1] * transition_mat[prev_index][curr_index])   \n",
    "\n",
    "    max_temp_index = temp.index(max(temp))\n",
    "    best_prev_tag = prev_states[max_temp_index]\n",
    "    cache[index]['&&'] = [best_prev_tag, max(temp)]\n",
    "\n",
    "    # Backtracing to extract the best possible tags for the \n",
    "    pred_tags = []\n",
    "    all_word_index = cache.keys()\n",
    "    last_word_index = max(all_word_index)\n",
    "    \n",
    "    for index in range(len(all_word_index)):\n",
    "        \n",
    "        word_index = last_word_index - index\n",
    "        \n",
    "        if word_index == last_word_index:\n",
    "            pred_tags.append(cache[word_index]['&&'][0])\n",
    "            \n",
    "        if word_index < last_word_index and word_index > 0:\n",
    "            pred_tags.append(cache[word_index][pred_tags[len(pred_tags)-1]][0])\n",
    "            \n",
    "    predicted.append(list(reversed(pred_tags)))\n",
    "\n",
    "    return predicted[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3fhhdah6Ij0X",
    "outputId": "3e3b44b2-6667-4749-8e2f-4ec807c03eb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DT0', 'PUQ', 'NN2', 'PUQ', 'VBB', 'PRF', 'CRD', 'NN2', 'PUN']\n",
      "['AJ0', 'NN1', 'NN1', 'PRP', 'CRD', 'NN1', 'PUL', 'NN0', 'PUR', 'NN2', 'PUN']\n"
     ]
    }
   ],
   "source": [
    "print(Viterbi(['These', '‘', 'communities', '’', 'are', 'of', 'two', 'kinds', '.']))\n",
    "print(Viterbi(['Average', 'foot', 'position', 'for', '11', 'stone', '(', '70kg', ')', 'sailors', '.']))\n",
    "\n",
    "# ['DT0', 'PUQ', 'NN2', 'PUQ', 'VBB', 'PRF', 'CRD', 'NN2', 'PUN']\n",
    "# ['AJ0', 'NN1', 'NN1', 'PRP', 'CRD', 'NN1', 'PUL', 'NN0', 'PUR', 'NN2', 'PUN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Nylw27xoIj0X"
   },
   "outputs": [],
   "source": [
    "def get_predictions(data):\n",
    "    pred = []\n",
    "    for index, sentence in enumerate(data):\n",
    "        if len(sentence) != 0:\n",
    "            pred.append(Viterbi(sentence))\n",
    "        else:\n",
    "            pred.append([])\n",
    "        if ((index+1) % 10000==0):\n",
    "            print(\"Predicted: %d \" % (index+1))  \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "kjbpc5g1Ij0X",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 10000 \n",
      "Predicted: 20000 \n",
      "Predicted: 30000 \n",
      "Predicted: 40000 \n",
      "Predicted: 50000 \n",
      "Predicted: 60000 \n",
      "Predicted: 70000 \n",
      "Predicted: 80000 \n",
      "Predicted: 90000 \n",
      "Predicted: 100000 \n",
      "Predicted: 110000 \n",
      "Predicted: 120000 \n",
      "Predicted: 130000 \n",
      "Predicted: 140000 \n",
      "Predicted: 150000 \n",
      "Predicted: 160000 \n",
      "Predicted: 170000 \n",
      "Predicted: 180000 \n",
      "Predicted: 190000 \n",
      "Predicted: 200000 \n"
     ]
    }
   ],
   "source": [
    "preds = get_predictions(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "WecXwo3mIj0X"
   },
   "outputs": [],
   "source": [
    "def get_accuracy(test_data, test_labels, preds):\n",
    "    \n",
    "    correct = 0\n",
    "    incorrect = 0\n",
    "    \n",
    "    print(\"Total: %d\" % len(test_data))\n",
    "    \n",
    "    t0 = time.process_time()\n",
    "    \n",
    "    for index, pred_labels in enumerate(preds):\n",
    "        true_labels = test_labels[index]\n",
    "        \n",
    "        for i, pred_label in enumerate(pred_labels):\n",
    "            if pred_label in true_labels[i]:\n",
    "                correct = correct + 1\n",
    "            else:\n",
    "                incorrect = incorrect + 1\n",
    "                \n",
    "    print(\"Evaluated Words: %d \" % (incorrect + correct))   \n",
    "    print(\"Correct: %d \" % (correct))   \n",
    "    print(\"Incorrect: %d \" % (incorrect))   \n",
    "    print(\"Time Taken: %.2f \\n \" % (time.process_time()-t0))\n",
    "    \n",
    "    print(\"Final Accuracy = %.06f\"  % (correct/(correct+incorrect)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "x7cX37MgIj0X"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 200468\n",
      "Evaluated Words: 4094999 \n",
      "Correct: 4016270 \n",
      "Incorrect: 78729 \n",
      "Time Taken: 0.63 \n",
      " \n",
      "Final Accuracy = 0.980774\n"
     ]
    }
   ],
   "source": [
    "get_accuracy(test_data, test_labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "7aLEXUw2KRc6"
   },
   "outputs": [],
   "source": [
    "tags = list(tag_dict.keys())\n",
    "def get_confusion_matrix(preds, test_labels):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for i in preds:\n",
    "        for j in i:\n",
    "            y_pred.append(j)\n",
    "    for i in test_labels:\n",
    "        for j in i:\n",
    "            y_true.append(j)\n",
    "    plt.figure(figsize=(25, 22), dpi=10)\n",
    "    df_cm = pd.DataFrame(metrics.confusion_matrix(y_true, y_pred, tags), tag_dict.keys(), tag_dict.keys())\n",
    "    sn.set(font_scale=1.0)\n",
    "    sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 5}) # font size\n",
    "    # plt.show()\n",
    "    # plt.savefig('confusion_matrix.png')\n",
    "    plt.savefig('cm_hmm.png', format='png', dpi=200)\n",
    "    # print(metrics.confusion_matrix(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 189
    },
    "id": "8GfUS-fbNuBk",
    "outputId": "dcf9762f-42db-45a3-8235-794900d4bffc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aseem/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:68: FutureWarning: Pass labels=['VVB', 'NN1', 'POS', 'NN2', 'PRP', 'NP0', 'VVZ', 'AT0', 'PRF', 'AJ0', 'ORD', 'DT0', 'VM0', 'VVI', 'TO0', 'VHI', 'PNI', 'VBZ', 'XX0', 'AV0', 'CJC', 'PNP', 'PNQ', 'DPS', 'VHZ', 'VVN', 'NN0', 'CJT', 'CJS', 'AVQ', 'AVP', 'DTQ', 'AJS', 'VHD', 'CRD', 'VVG', 'VVD', 'VBD', 'VBG', 'VBI', 'AJC', 'UNC', 'VHB', 'VBN', 'PNX', 'VHG', 'EX0', 'VBB', 'VDN', 'VDD', 'ITJ', 'ZZ0', 'VHN', 'VDB', 'VDZ', 'VDI', 'VDG', 'PUN', 'PUQ', 'PUL', 'PUR'] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 250x220 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_confusion_matrix(preds, test_labels)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "POS-Tagger-HMM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
