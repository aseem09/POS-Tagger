{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "POS-Tagger-HMM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Sbq6xDXIj0T"
      },
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import pprint\n",
        "import pickle\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import multiprocessing\n",
        "import time\n",
        "from numpy import asarray\n",
        "from numpy import savetxt\n",
        "pp = pprint.PrettyPrinter(indent=4)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LzLsddKIj0U"
      },
      "source": [
        "import operator\n",
        "\n",
        "def get_column(list_, n):\n",
        "    return map(operator.itemgetter(n), list_)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rm9MeicGIj0U"
      },
      "source": [
        "def parse_data(file):\n",
        "    \n",
        "    tree = ET.parse(file)\n",
        "    root = tree.getroot()\n",
        "    \n",
        "    data = []\n",
        "    labels = []\n",
        "    \n",
        "    for s_tag in root.iter('s'):\n",
        "        \n",
        "        sentence = []\n",
        "        tags = []\n",
        "        \n",
        "        for e_tag in s_tag:\n",
        "            \n",
        "            if e_tag.tag == 'w':\n",
        "                word = e_tag.text.replace(\" \", \"\")\n",
        "                tag = e_tag.attrib['c5']\n",
        "                    \n",
        "                sentence.append(word)\n",
        "                tags.append(tag)\n",
        "                \n",
        "            elif e_tag.tag == 'c':\n",
        "                if e_tag.text is not None:\n",
        "                    tag = e_tag.attrib['c5']\n",
        "                    word = e_tag.text.replace(\" \", \"\")\n",
        "                    \n",
        "                    sentence.append(word)\n",
        "                    tags.append(tag)\n",
        "                    \n",
        "            elif e_tag.tag == 'mw':\n",
        "                tag = e_tag.attrib['c5']\n",
        "                word = \"\"\n",
        "                for w_tag in e_tag.iterfind('w'):     \n",
        "                    word += w_tag.text.replace(\" \", \"\")\n",
        "                \n",
        "                sentence.append(word)\n",
        "                tags.append(tag)\n",
        "                \n",
        "            elif e_tag.tag == 'hi':\n",
        "                \n",
        "                for w_tag in e_tag.iterfind('w'):     \n",
        "                    word = w_tag.text.replace(\" \", \"\")\n",
        "                    tag = w_tag.attrib['c5']\n",
        "                        \n",
        "                    sentence.append(word)\n",
        "                    tags.append(tag)\n",
        "                \n",
        "        data.append(sentence)\n",
        "        labels.append(tags)\n",
        "\n",
        "    return data, labels"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QpNALZSIj0U"
      },
      "source": [
        "def load_dataset(path):\n",
        "\n",
        "    data = []\n",
        "    labels = []\n",
        "\n",
        "    for subdir, dirs, files in os.walk(path):\n",
        "        for file in files:\n",
        "\n",
        "            fileName = subdir + '/' + str(file)\n",
        "            file_data, file_labels = parse_data(fileName)\n",
        "            data.extend(file_data)\n",
        "            labels.extend(file_labels)\n",
        "\n",
        "    return data, labels"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfD563pVIj0U"
      },
      "source": [
        "# Load Dataset\n",
        "\n",
        "train_path = 'Train-corpus/'\n",
        "test_path = 'Test-corpus/'\n",
        "\n",
        "data, labels = load_dataset(train_path)\n",
        "test_data, test_labels = load_dataset(test_path)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utQnqd6EIj0U",
        "outputId": "4d0faee0-87c6-44c8-fc9e-ab8ef8803687"
      },
      "source": [
        "print(len(data))\n",
        "print(len(labels))\n",
        "\n",
        "print(data[0])\n",
        "print(labels[0])\n",
        "\n",
        "print(len(test_data))\n",
        "print(len(test_labels))\n",
        "\n",
        "print(test_data[11])\n",
        "print(test_labels[11])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=10.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkES1f_ROwPn"
      },
      "source": [
        "# Load JSON Files\n",
        "\n",
        "with open('words.json') as f:\n",
        "    word_dict = json.load(f)\n",
        "with open('tags.json') as f:\n",
        "    tag_dict = json.load(f)\n",
        "with open('word_tags.json') as f:\n",
        "    word_tags_dict = json.load(f)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6XVaCmZOwPs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c487106-7292-462d-affc-12c5ae84266d"
      },
      "source": [
        "print(len(tag_dict))\n",
        "print(len(word_dict))\n",
        "print(len(word_tags_dict))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=10.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lwq6kxsqIj0V"
      },
      "source": [
        "def compute_word_tag_freq_matrix():\n",
        "    \n",
        "    rows = len(word_dict.keys())\n",
        "    cols = len(tag_dict.keys())\n",
        "    \n",
        "    mat = [[0 for i in range(cols)] for j in range(rows)] \n",
        "    \n",
        "    i=0\n",
        "    for word in word_dict.keys():\n",
        "        j=0\n",
        "        for tag in tag_dict.keys():\n",
        "            case = word + \"_\" + tag\n",
        "            if case in word_tags_dict.keys():\n",
        "                mat[i][j] = word_tags_dict[case]\n",
        "            j = j + 1\n",
        "        i = i + 1\n",
        "        \n",
        "    return mat"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTZCbh_dIj0V"
      },
      "source": [
        "freq_matrix = compute_word_tag_freq_matrix()\n",
        "savetxt('freq_matrix.csv', freq_matrix, delimiter=',')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CqThn1vIj0W"
      },
      "source": [
        "def compute_emission_prob_matrix(freq):\n",
        "    rows = len(freq_matrix)\n",
        "    cols = len(freq_matrix[0])\n",
        "    mat = freq\n",
        "    \n",
        "    for j in range(0, cols):\n",
        "        col_slice = list(get_column(mat, j))\n",
        "        total = sum(col_slice)\n",
        "        for i in range(rows):\n",
        "            mat[i][j] = mat[i][j]/total\n",
        "    \n",
        "    return mat"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSlaZA_xIj0X"
      },
      "source": [
        "emission_mat = compute_emission_prob_matrix(freq_matrix)\n",
        "savetxt('emission_mat.csv', emission_mat, delimiter=',')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66SH1AP2Ij0X",
        "outputId": "167a7cbf-df0a-4546-bd05-d5e774eedfb3"
      },
      "source": [
        "tags_index_dict = dict(zip(list(tag_dict.keys()),range(0, len(tag_dict.keys()))))\n",
        "word_index_dict = dict(zip(list(word_dict.keys()),range(0, len(word_dict.keys()))))\n",
        "tags_inv_dict = {v: k for k, v in tags_index_dict.items()}\n",
        "word_inv_dict = {v: k for k, v in word_index_dict.items()}\n",
        "print(tags_index_dict)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=10.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtZkdB-gIj0X"
      },
      "source": [
        "def get_index(tag, isPrev=True):\n",
        "    if tag == \"start\":\n",
        "        return [0]\n",
        "    if tag == \"end\":\n",
        "        return [len(tags_index_dict.keys())]\n",
        "    if \"-\" in tag:\n",
        "        a1 = tags_index_dict[tag[:3]]\n",
        "        a2 = tags_index_dict[tag[4:]]\n",
        "        return [a1, a2]\n",
        "    else:\n",
        "        a = tags_index_dict[tag]\n",
        "        return [a]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEEzgXwHIj0X"
      },
      "source": [
        "def compute_tag_tag_frequency_matrix(data, labels):\n",
        "    \n",
        "    rows = len(tag_dict.keys()) + 1\n",
        "    cols = len(tag_dict.keys()) + 1\n",
        "    \n",
        "    mat = [[0 for i in range(cols)] for j in range(rows)] \n",
        "    \n",
        "    i=0\n",
        "    for sentence in data:\n",
        "        prev_tag = \"start\"\n",
        "        curr_tag = \"start\"\n",
        "        \n",
        "        j=0\n",
        "        for word in sentence:\n",
        "            prev_tag = curr_tag\n",
        "            curr_tag = labels[i][j]\n",
        "            \n",
        "            prev_index = get_index(prev_tag)\n",
        "            curr_index = get_index(curr_tag)\n",
        "            \n",
        "            a1=0\n",
        "            a2=0\n",
        "            b1=0\n",
        "            b2=0\n",
        "            \n",
        "            if len(prev_index) == 1:\n",
        "                a = prev_index[0]\n",
        "                if prev_tag != \"start\":\n",
        "                    a = a + 1\n",
        "                if len(curr_index) == 1:\n",
        "                    b = curr_index[0]\n",
        "                    mat[a][b] = mat[a][b] + 1\n",
        "                else:\n",
        "                    b1 = curr_index[0]\n",
        "                    b2 = curr_index[1]\n",
        "                    mat[a][b1] = mat[a][b1] + 1\n",
        "                    mat[a][b2] = mat[a][b2] + 1\n",
        "                    \n",
        "            else:\n",
        "                a1 = prev_index[0] + 1\n",
        "                a2 = prev_index[1] + 1\n",
        "                if len(curr_index) == 1:\n",
        "                    b = curr_index[0]\n",
        "                    mat[a1][b] = mat[a1][b] + 1\n",
        "                    mat[a2][b] = mat[a2][b] + 1\n",
        "                    \n",
        "                else:\n",
        "                    b1 = curr_index[0]\n",
        "                    b2 = curr_index[1]\n",
        "                    mat[a1][b1] = mat[a1][b1] + 1\n",
        "                    mat[a1][b2] = mat[a1][b2] + 1\n",
        "                    mat[a2][b1] = mat[a2][b1] + 1\n",
        "                    mat[a2][b2] = mat[a2][b2] + 1\n",
        "            \n",
        "            j=j+1\n",
        "            \n",
        "        curr_index = get_index(curr_tag)\n",
        "        \n",
        "        if len(curr_index) == 1:\n",
        "            b = curr_index[0] + 1\n",
        "            mat[b][61] = mat[b][61] + 1\n",
        "        else:\n",
        "            b1 = curr_index[0] + 1\n",
        "            b2 = curr_index[1] + 1\n",
        "            mat[b1][61] = mat[b1][61] + 1\n",
        "            mat[b2][61] = mat[b2][61] + 1\n",
        "            \n",
        "        i=i+1\n",
        "        \n",
        "    return mat"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWhRt0OhIj0X"
      },
      "source": [
        "tag_tag_freq_matrix = compute_tag_tag_frequency_matrix(data, labels)\n",
        "savetxt('tag_tag_matrix.csv',tag_tag_freq_matrix, delimiter=',')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2HWnRauIj0X"
      },
      "source": [
        "def compute_transition_prob_matrix(freq):\n",
        "    rows = len(freq)\n",
        "    cols = len(freq[0])\n",
        "    \n",
        "    mat = np.array(freq, dtype=float)\n",
        "    \n",
        "    for i in range(0, rows):\n",
        "        \n",
        "        total = float(sum(mat[i]))\n",
        "        if total == 0:\n",
        "            total = 1\n",
        "            \n",
        "        mat[i] = [x/total for x in mat[i]]\n",
        "            \n",
        "    return mat"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shjbRkjkIj0X"
      },
      "source": [
        "transition_mat = compute_transition_prob_matrix(tag_tag_freq_matrix)\n",
        "savetxt('transition_matrix.csv', transition_mat, delimiter=',')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1ccMioeIj0X"
      },
      "source": [
        "possible_tags = {}\n",
        "count = 0\n",
        "\n",
        "def compute_possible_combinations(data, labels):\n",
        "    \n",
        "    for i, sentence in enumerate(data):\n",
        "        for j, word in enumerate(sentence):\n",
        "            label = labels[i][j]\n",
        "            \n",
        "            if \"-\" in label:\n",
        "                l1 = label[:3]\n",
        "                l2 = label[4:]\n",
        "                try:\n",
        "                    if l1 not in possible_tags[word]:\n",
        "                        possible_tags[word].append(l1)\n",
        "                    if l2 not in possible_tags[word]:\n",
        "                        possible_tags[word].append(l2)\n",
        "                except:\n",
        "                    init = []\n",
        "                    init.append(l1)\n",
        "                    init.append(l2)\n",
        "                    possible_tags[word] = init\n",
        "            else:\n",
        "                try:\n",
        "                    if label not in possible_tags[word]:\n",
        "                        possible_tags[word].append(label)\n",
        "                except:\n",
        "                    init = []\n",
        "                    init.append(label)\n",
        "                    possible_tags[word] = init\n",
        "            \n",
        "compute_possible_combinations(data, labels)\n",
        "compute_possible_combinations(test_data, test_labels)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0ZEeFF3Ij0X"
      },
      "source": [
        "# Use Laplace Smoothing\n",
        "def probability_word_given_tag(word, tag):\n",
        "    \n",
        "    count_tag = tag_dict[tag]\n",
        "    \n",
        "    if word+'_'+tag in word_tags_dict.keys():\n",
        "        count_word_tag = word_tags_dict[word+'_'+tag]\n",
        "\n",
        "        return (count_word_tag)/(count_tag)\n",
        "    \n",
        "    else:\n",
        "        return 1/(count_tag + 1)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPdLC9XpIj0X"
      },
      "source": [
        "def Viterbi(sentence):\n",
        "    predicted = []\n",
        "    cache = {}\n",
        "    for index, word in enumerate(sentence):\n",
        "        if index == 0:\n",
        "            cache[index] = {}\n",
        "            tags = possible_tags[word]\n",
        "            for tag in tags:\n",
        "\n",
        "                if word in word_dict.keys():\n",
        "                    word_index = word_index_dict[word]\n",
        "                    tag_index = tags_index_dict[tag]\n",
        "\n",
        "                    cache[index][tag] = ['##', transition_mat[0][tag_index] * emission_mat[word_index][tag_index]]\n",
        "\n",
        "                else:\n",
        "                    tag_index = tags_index_dict[tag]\n",
        "                    cache[index][tag] = ['##', transition_mat[0][tag_index] * probability_word_given_tag(word, tag)]\n",
        "\n",
        "        else:\n",
        "            cache[index] = {}\n",
        "            prev_states = list(cache[index-1].keys())\n",
        "\n",
        "            tags = possible_tags[word]\n",
        "            for tag in tags:\n",
        "                temp = []\n",
        "                for prev_state in prev_states:\n",
        "                    case = word + \"_\" + tag\n",
        "                            \n",
        "                    if word in word_dict.keys():\n",
        "                        word_index = word_index_dict[word]\n",
        "                        curr_index = tags_index_dict[tag]\n",
        "                        prev_index = tags_index_dict[prev_state]+1\n",
        "\n",
        "                        temp.append(cache[index-1][prev_state][1] * transition_mat[prev_index][curr_index] * emission_mat[word_index][curr_index])\n",
        "                    else:\n",
        "                        curr_index = tags_index_dict[tag]\n",
        "                        prev_index = tags_index_dict[prev_state]+1\n",
        "                        temp.append(cache[index-1][prev_state][1] * transition_mat[prev_index][curr_index] * probability_word_given_tag(word, tag))\n",
        "                        \n",
        "                max_temp_index = temp.index(max(temp))\n",
        "                best_prev_tag = prev_states[max_temp_index]\n",
        "                cache[index][tag] = [best_prev_tag, max(temp)]\n",
        "    \n",
        "    index = len(sentence)\n",
        "    cache[index] = {}\n",
        "    prev_states = list(cache[index-1].keys())\n",
        "    \n",
        "    temp = []\n",
        "    for prev_state in prev_states:\n",
        "\n",
        "        curr_index = 61\n",
        "        prev_index = tags_index_dict[prev_state] + 1\n",
        "\n",
        "        temp.append(cache[index-1][prev_state][1] * transition_mat[prev_index][curr_index])   \n",
        "\n",
        "    max_temp_index = temp.index(max(temp))\n",
        "    best_prev_tag = prev_states[max_temp_index]\n",
        "    cache[index]['&&'] = [best_prev_tag, max(temp)]\n",
        "\n",
        "    # Backtracing to extract the best possible tags for the \n",
        "    pred_tags = []\n",
        "    all_word_index = cache.keys()\n",
        "    last_word_index = max(all_word_index)\n",
        "    \n",
        "    for index in range(len(all_word_index)):\n",
        "        \n",
        "        word_index = last_word_index - index\n",
        "        \n",
        "        if word_index == last_word_index:\n",
        "            pred_tags.append(cache[word_index]['&&'][0])\n",
        "            \n",
        "        if word_index < last_word_index and word_index > 0:\n",
        "            pred_tags.append(cache[word_index][pred_tags[len(pred_tags)-1]][0])\n",
        "            \n",
        "    predicted.append(list(reversed(pred_tags)))\n",
        "\n",
        "    return predicted[0]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fhhdah6Ij0X",
        "outputId": "3e3b44b2-6667-4749-8e2f-4ec807c03eb8"
      },
      "source": [
        "print(Viterbi(['These', '‘', 'communities', '’', 'are', 'of', 'two', 'kinds', '.']))\n",
        "print(Viterbi(['Average', 'foot', 'position', 'for', '11', 'stone', '(', '70kg', ')', 'sailors', '.']))\n",
        "\n",
        "# ['DT0', 'PUQ', 'NN2', 'PUQ', 'VBB', 'PRF', 'CRD', 'NN2', 'PUN']\n",
        "# ['AJ0', 'NN1', 'NN1', 'PRP', 'CRD', 'NN1', 'PUL', 'NN0', 'PUR', 'NN2', 'PUN']"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=10.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nylw27xoIj0X"
      },
      "source": [
        "def get_predictions(data):\n",
        "    pred = []\n",
        "    for index, sentence in enumerate(data):\n",
        "        if len(sentence) != 0:\n",
        "            pred.append(Viterbi(sentence))\n",
        "        else:\n",
        "            pred.append([])\n",
        "        # if ((index+1) % 10000==0):\n",
        "            # print(\"Predicted: %d \" % (index+1))  \n",
        "    return pred"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "kjbpc5g1Ij0X"
      },
      "source": [
        "preds = get_predictions(test_data)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WecXwo3mIj0X"
      },
      "source": [
        "def get_accuracy(test_data, test_labels, preds):\n",
        "    \n",
        "    correct = 0\n",
        "    incorrect = 0\n",
        "    \n",
        "    # print(\"Total: %d\" % len(test_data))\n",
        "    \n",
        "    t0 = time.process_time()\n",
        "    \n",
        "    for index, pred_labels in enumerate(preds):\n",
        "        true_labels = test_labels[index]\n",
        "        \n",
        "        for i, pred_label in enumerate(pred_labels):\n",
        "            if pred_label in true_labels[i]:\n",
        "                correct = correct + 1\n",
        "            else:\n",
        "                incorrect = incorrect + 1\n",
        "                \n",
        "    # print(\"Evaluated Words: %d \" % (incorrect + correct))   \n",
        "    # print(\"Correct: %d \" % (correct))   \n",
        "    # print(\"Incorrect: %d \" % (incorrect))   \n",
        "    # print(\"Time Taken: %.2f \\n \" % (time.process_time()-t0))\n",
        "    \n",
        "    # print(\"Final Accuracy = %.06f\"  % (correct/(correct+incorrect)))"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7cX37MgIj0X"
      },
      "source": [
        "get_accuracy(test_data, test_labels, preds)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q01Jfcj_O6sB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aLEXUw2KRc6"
      },
      "source": [
        "from sklearn import metrics\n",
        "import seaborn as sn\n",
        "tags = list(tag_dict.keys())\n",
        "def get_confusion_matrix(preds, test_labels):\n",
        "    # print(preds[0][0])\n",
        "    # print(test_labels[0])\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    for i in preds:\n",
        "        for j in i:\n",
        "            y_pred.append(j)\n",
        "    for i in test_labels:\n",
        "        for j in i:\n",
        "            y_true.append(j)\n",
        "    plt.figure(figsize=(25, 22), dpi=10)\n",
        "    df_cm = pd.DataFrame(metrics.confusion_matrix(y_true, y_pred, tags), tag_dict.keys(), tag_dict.keys())\n",
        "    sn.set(font_scale=1.0)\n",
        "    sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 5}) # font size\n",
        "    # plt.show()\n",
        "    # plt.savefig('confusion_matrix.png')\n",
        "    plt.savefig('cm_hmm.png', format='png', dpi=200)\n",
        "    # print(metrics.confusion_matrix(y_true, y_pred))\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        },
        "id": "8GfUS-fbNuBk",
        "outputId": "dcf9762f-42db-45a3-8235-794900d4bffc"
      },
      "source": [
        "get_confusion_matrix(preds, test_labels)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 250x220 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAALoAAACsCAYAAADMgbZ3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAGKAAABigEzlzBYAAAXYElEQVR4nO2dbXAUR3rH/1pJIMSBJQsMkhB6ZZEEWhCS0IK0sh1HzsWXOp/tkCvukio7uVS5Us75y8VJ5eVSubxUyjl/8AUHTBywywEKEVuKjHRGvFlAYc5gX/yiisEXjCwjIGbBNsZIaF/yYTOzs7vT8/Tuzu7MrJ6fa0rjfnq6n1l2u//d0/N0XjgcDkOH8pJmAMBnX3+hZ844eZpzXQeZnCFw+yKZZ+bqeTJP4aI6oa0gKY8YxipCwbQudwHA6Ogodu7cGWPY0NWOZcsr0OPzYn1HK6qqKgAAbne9+ldr6/F5UV9fo16vzadN83iaY8praKgFAPT4vGo+jyfSm/h8XmE5MmlKOXr5jMqJv2e9cvTSmppWJOWrtj6Zzw6A6pP2PNn6ZNKSvZd0fSAJh+jDgDyRdCmYUwkAuDV5HAAwr8JnXJDiD+GvbD5m9iAjXW5PjpF55lSsEtqkpIvgt8Aw2SNk3GJTuACgr68Pp0+fjjEoXXdp3d24s/4eLCiai+LCufA0NwKISg4g0oX6fF6s0HRFSldcXb1MTXO76+HzedHR0Yq6ump4PM3o8XlRVVWhKwu0XXoy3aVIbgFAc7M74Ro92eDr7ozxJb4cPb8U+aVNU+4/Pi1e9un529LSlFC3Nk2vPjOki9amfA7adEpmGcke0TUkwRn6MICULgrFhXPV869npuUdZBgCKely4QyZZ05Nu9DmAoADBw6gv78/waj95a1uaUR7+xosX14ZY4vPJ5OWyjWptN7Z8sEOn4Md69PrAUV2inAwQB5+vx83btzQvV66RdfysyX3AgB+eOWotKMMI0KmRZ/+6CSZZ+6KjRgeHkZhYWFMem9vL8+jMw6B0OAKDzzwgG66OhgdHR1NMCpdizK4UNIqvI0oa6yKSVMkxP29d6sDTG0Z2nOzutX4gW6m6jMaXGXLB720XJJrJJmeRzfi3MrovKX7LD3PmQvw0gTzkZIuHxwk88xd3Su0sXRhnIEZ8+gAsGPHDoyMjKiGxsYG9Xz16kb1XCtnfnDXAvzgrgXonfoCm8s78aT3wYR8el1WvBQSXaOdTxctQ9C7Vjs/r1wvU59emvZzcLujzwFq66rVNKOZH7159Pj7S8av+Dn4ZK6VvWftuXbJgZXSJRyaIQ8j0pIuWjaXRx4s7Ln0i6SuYxgZ6TL19gCZp6jtO0KbCwC2b9+OQ4cOSTml9yvU/uoVqKdjetfqDfCMWkTZuVttmraFli3b7AVOil/aFj2+5xCVo+0N03kyKjuI1ut9LRmMhoL0YYCwRf+1+x7BxcnLqKxYiqmpaVz1X8P58+MAIh/w1NQ0Ll2+gomJSTUNAK5fuYaJTyK/0M+nbiaUq3ctM7uRatFP7SXzFHm/K7SZJl0USormq+d6X3SGiUfqi/7mHjJP0YbNQpu6Hn1gYCDBKOqCRIOhhoZabOzqwLp2D6oMlgoYlZ2tNNlrUhkwZnJwmI6kMstvS6RLIEAfBpjeomu5+khkpeCiV86lXRaTu8i06LeOvUjmmdfzqNBWAACBQAAFBTylztiYoHGLTeECgLGxMWzZsiXBmO5cqmt5PfKb1qQ1c5JOmrKW2mnduJX1xctSvWcQ1sy6hOjDgIxKF4WHyqPrhPsv0euKmdmFlHQZ+Rcyz7z7/0hoY73COANi0RZFzBKAEydOxBjN6kL7L52Bv6EA/oYCHPU8hJ+XdmO0fZMpZeul5SGy+KrGQDIZlZMHYKVNpIST67PlrEv8gNRM6aLl56XdAIDfvH6CyJk66a4w5EgF2UVKugz+lMwz79s/EtrUFn1sbAxnzkT1s/Jico8mtgoQ/RVqX41qbnZLxyb5RnM1Sjc0JQxQ9QY9ei8yG5Wt/PX9/4CqTrPwKplytNcnc63si9yyL0ebVV+yLbD2sb/2JXhLW3Qr16OnQ2F+tPeYSXPqiHE2Ui36q/9A5pn38J8LbTwYZZyBGevRn3/+efT39ye8Qa10LbIr3WTzAcCKFXXo7u5ER8faBBkT382LysnVgVmu1GeqdAkG6cMAy6SLlo7FUS1++rP0lwvw627OQkq67PlrMs+8zX8jtLF0YZyBGUsAtmzZgoMHE18+VboW2ZG3zMsD8dF03e56tHrXoLm1CUuXLRGWnc1ZF720HkGZVkqJZGWdWX5bIl2csAQgGeruKAcAnP/ikiX1M9lHSrrsfIrMM++xp4U2li6MMzBj1mVwcBB79+7FrVu3VMMaTzPyXZHnSbLvDcrmM7Iv81RjkXspHmztQefilXi4417pa5NJM7Kn+gDHKM0oEkEm6ss16RIOBsnDCKF0mVsUicQVTPOXlCqdi1eq57/47KwlPjDZQUa6fL3tSTJP8ePPCm3qEoDR0VGMj4+rBp/PmxDDHND/NSpxX2QGo/Gtl3agq/QIStparwfLatOP3qs3gEvGR6MtYsxq3fRe2aPyZXIwmu3nFyS5MI9OsbI08qGfvf6pxZ4wmUCqRX/2cTJP8ZPbhDYejDLOQGJ7Ib/fjyNHjqCkpCQmvbe3NyJdwuGw7ly6TLdEbb+it6JRtmzlvH1DK1rWrTJcKpBLA7NMyQs73zNJIEgeZWVl2LRpE3p7e2MOwCHSRUGZBQKsGyQz5iMlXf7p98k8xX+yQ2hj6cI4gnDAhA11AWD//v0xsy6A+d1XOkHz3e56dHWtR1vbGlTXVKHAlY+mlanHBUzmmmxvLptMWjJz8Gb5bYl0CYXpwwBHSRctBa58AEAgza2zGeuRkS43f/J9Ms/8H+8S2tQWfXh4GK+88kqM0a6DMLe7Hj5fZC270SIro0FyJu/PKC2Z7dDt+LlnygeSXFvUlSyVC8rU84s3/BZ6wqSKVIv+V79D5pn/t31CGw9GGWdAaHAKFwBs3bqVjKab6vYlme5COze2YW1bC5bl0A5tsmmzaR49HAiShxGOly5alNjsHJfdWchIl69+9CCZ5xs//U+hjaUL4wzMkC5HjhwxfJXObl22KE3ZhEBmqUAm78/qz8HM+tJ99iHrA0U4ECIPI9KSLma9bW/2W/t/WX6Pev53l94woUQmk8hIlxtP6G99rmXBlmGhjTcCYJwB0WJTuABg27ZtwpWLRo+YWzzNMZvLygSN13uRo8XTDJ/PG7NJLRAN5K9XjlHa4OL/xbGGKbw851d4tGID/rT7kaTL0XvBQYkxqY0GoPUxfuMB7WdH1SvzECn+3yKZWZf4z13vs9Veo7z8YvbDLZGdIhwOk4cROTXrosejFRsAAC9OvmmxJ4wIGeny5R/0knkW/lviOFNBXQKwZcuWmGi6QG7M57o7m+HubLZsexm7fA52v2eKcChMHkbkfIuu8GcVd6vn/zg5aqEnTDwyLfoXv3cfmeeOlw8LbTwCZRwB1WJTxKxe3LEj9g0NpWuRDUkn+yY7Zc9UWk1nI2o6G2NkjF6IvEz7JRMtIRNpqVxjl8EoAmH6MGDWSBctylp2gNez2wEZ6XJ90z1kntJ9bwhtLF0YRxAmWmwKFxCRLUYb6sp2S7Jdciplm5m2sasD69o8WF6zDCtLl+E32jda4leu12fqrEuAPoyYldJFCwdHsh4Z6eL/1t1knrIh8Wya+mT08OHEqZlcbFlET1ut8CvX6+MW3Ub0+LyYmpqG/+o1jI9HWnUeoGYXmRb9s166RV98UNyiz/rB6LHjpwDEzsQw9iOU5g6dLiAS02VoaAgzMzMxRr0uxozIsqlcI0ozesUvGR9EUQXM9DWTn4Md6zNTuiCcRx8GzHrpokfrosg/wC+v/k9W6pvtW7LLSJdL3feSecpPHBXaZr10YZwBsQM6iQuIbALQ1xcbE0M7J0492lceqcts7SIjNZQlB3r1GpWdTJqRfZ13DVa1NpkavdfIB9EueixdooSCeeRhBEsXA4oK5qjnU4HbFnqS28hIl4mO+8g8xa/3YWRkBIsWLYpJ7+3tZenCOAOqxQaAsrIybN68WdfmAoC+vj7dKABGkqSlpUlNU1a4adOMZmcou54sMqsLlX2rvbp6GdZvWAdP6yosqbwLC+cWY93qVab4YNa9JBvlN5X6ZFeusnTJERbOLQYAfDn9tcWe5B4y0uV8y/1knrr3R4S2mFfpzp6N3eYwWwMS0c532fSBSlu1uhEbu9Y7enuZbNeXMy262fFYnEDVguhAZ+LGVQs9yR1kWvRzTd8k87j/+3WhjQejjCMIBV10JgMMowAoUkL5C8R2O/Hzv7IDPcpuxmBUG3BfO0hO14emVW50bmxDZVVF2q/hmbFjXzJpmSw709IlHKYPI3gwmgbKLnm8Q156yEiXD+p+i8yz+vx+oY1D0jGOIEws2qJQX7x47bXXcPt27NM/p3ahMssMzCjb5/PC5/Om/Og+05+D1fWZKV2CoTzyMIKliwkoc+wAz7Ongox0+eVyeiOA1k+IjQBYujB2h2qxKVTpMjKS+FRJ6VqMViX2+LyGswh6XZbeY2XRNalsZptJ6aKXtna9B42elShdemdSSwXM9MGO9Zk765JHHkawdDEZXiqQPDLS5VTFw2Qe7+SrQpsLiMyh59Jg1EofNnatR1v7GltuL5Pt+swdjLrIwwhu0TPEbFwekSoyLfrxpb9N5vFd/g+hTR2B8oCUsTNBM+bRAWBsbCzljQBkBq3JlJNuWrYHo6I07RKJTPhg5w0YkvWBIoQ88jCCpUsWKC6cCwD4embaYk/siYx0Objku2Se3it7hTbWKowjCBMtNoUawGj//v24ceNGjNGK0b/RLnjZ8sHstIameqxeG9lHqaGkAr1tG7LuQzrlmPlijMhOEZA4jGDpkkUaSqLLnX/1+aSFntgLGekytET/pWct37qyR2hzAcCuXbuwZ09iJtlfq/JENJmtXZRrZMvWa/mTbVmy1VsYpXVsWAfPulUZjxljRoueic9LZKcI5OWRhxHcolsEv5IXRaZFH1j6PTLPdy7vFtp4MMo4AqrFplBD0g0MDOhG05XpvoxCyMl2h0bXpJpmNM+cifqSSevc2Ia1bS2otHHkg2z6QBGWOIxg6aJDtqPbri2rAwD8l/98lmq0FzLSZU/F98k8myd3CW0sXRhHEDRjHn10dDRh1kUrL2Sj6cp0X8nOyaYTki5V6SIT3VZ21kimG1+3YS2qauUiKMxW6RLKow8jWLrYiNo7lqrnH39x2UJPsouMdNlZ+btknscu/rvQxtKFcQRpvkkXkS5bt25N64FRLnWhVvpQ5anBYnc5QiUFyAOwchbcsywySwD8fj/27duHgwcPxhwASxfbMpv2NZKRLtuqaOny+IRYuqgtumgeHZB/tJ8LLYtdfMjEdi92vmcKXtSV45QUzVfPP5+6aaEnmUOmRf9niRb9jw1adB6MMo4gYMZgFIjIl/Hx8RjjbJUNdvIhsgFBB6qWV5pan9lyNNPSJSRxGMHSxUHkavReGenydDUtXZ4al5AuHAWAsTPBNK83jAKgbKqrF0g/W7IhlSUAdokCQPmfbNldXevR1bUeDfU1cOXloXFl7sg1ihDC5GEESxcH4tKszQ5RWz04ABnp8pNqevXij8d59SLjcNIdlbgAYPv27Th58mRM7EXlZQqRDNAGK6qqqhDm09vXSJFE2jTRNco5tT+SrMTRK8essmXL83V3St2zqL7u7k60t69FTe1yFLjy0bTS3MBRZu2tlEzUZIpAXpg8jGDp4nAKXPkAgEAo3eGadchIl7+ood8Z/fsL4ndG1bguL774YoLRyvljvTQzX8NL5hrZ7dyz9Tlo03y+TnR0rJVaKmCW31YMRgMIk4cR3KLnCErLDjivdZdp0Z+qoeO6PH1BHNeFB6OMI6BabAp19WJfX1+C0W7ShX0Qp4kkjFPumYKjADAJOG2pgIx0+WENHU33Zxc4mi7jcEyZRx8eHsbLL7+cYHRCl80+JKZ1da1HW9saQxljt3umCCJMHkawdGEsR0a6/GHNJjLPv17YJ7Sp8+hHjx7F1auxwS6d1pKxD4lpPRl4Jc+awSj9nxHcos8S7DzPLtOiP1bzCJln54VXhDYejM4y7PYll8WUwWh/f78a/0KLU7tsmbB3mfbBDp+DNk1mnt3O0iUYDpOHESxdZiEL5swDANy4fctiTyLISJfvVT9E5tk93i+0sXSZZShfcqdBTR9SqEsAdu7cmWBMtluyy4a6CkYRb7PlQ7qfg9krNhtW1GJj93q0ta+x1T5KFPwqHeN4ZKTLw9XfJvO8Oj4otLF0YRyBoD2WxgUAu3fvzvrqRTMC6TtlxsMuPujZlW0stVEFrLhnCn7xgjEFJbKAFVEFZKTLA8sfIPMMfzIstKktul22SM9W2mz0wcju83nRkYWlAiI7RTgcJg+/349nnnmG46MzNNpYntlq22Va9PurvknmGZl4XWjjwSjjCKjpQwqX9n/eeustTE1Nqf9vFF9EL/ZHc7M7IU3UfSlz7pnsshV/7CAb7OCDzDUeT3PMasdshSOkCIZD5GEESxfGcmSkyz3Lfp3M88anh4Q2li6MI6AWbVG4AGBgYMBw9SIVYq2hoVb3UXWym+emk6aEP6N8tSoAvjZNT/alUk6yofJky1bKVebYzfA1XenCSwAYxyMjXbwV95B5Tk2+IbSpr9JxXJfM12cHH9Ipx4zyqLJFcIvuAHp8XkxNTePS5SuYmJi02p2U6PF5cXHyMj4+H9nnyswnqDItenu5j8xz5tJxoY2/6ExSZGKpgMwXfV15N5nnnUsnhDZ1CYAToumyD9bX5/N54XbXxaQpc+/xkw5mSheeR2ccj0yLvnqJl8zzwZVTQhvPozOOgIrbQqFKl6GhIczMzMQYla6Fmpu2Q5ed7Pr2TPhgh88hm/Vp59kzPevC0oWxHGXFY6ptrox0cS9uJ/Oc++yM0MbShXEEVItNoa5e3L17N8bHx2OMTulC2Yfs1ac3w9LiaYbP501rHyUKjr3IOB4Z6VJd5iHzjPvfE9rUwahRNF3ZeC12bcnYh+zVp13cZ2qLLvEqnRHcojMZ4ctnHwYALHzyVTKvTIteWbqKzHPx+pjQxoNRJmOkG4tFS7pLDlwAMDIyghdeeCHB6OQulH2wtr4zn17D2xevo6AgT+oailA4RB5GsHRhMsqqO6vV87Fr47p5ZKTLooVuMs/VL88JbSxdGEdgmnQZHBzE7du3Y4y50IWyD9be89i1cZStKsf8+jtRX1uDwvwCNDcmRmeg4CUAjGMozI8KiJlgQD2XkS4L59eReb68eV5oY+nCOALTlgCMjIxg+/btMcZc6kLZB+vvecPGdrSua0HFsqWqhNG28kaEwmHyMIKlC2MJ2i/4rVv6szFa5hZVkXmmpyaENnUwumPHjgRjrrYss9UHO91zd3dkl7zly6PvOhiRsSUADOM0/H4/5syZgwULFiTYXDr5GcaRlJWV4dQp/fdGuUVnZgWOaNEPHRJHSWXMJf6hYa6g+0XXxng5cyb6Ht7AwAAA4Pjx42qa8iU8fPiwmjY4GNkG77nnnlPTTp48CQB4++231bSvvvoqpgwAmJ6eBgBMTERH0B9++GFCWn9/dJdgpT5tOcr5O++8k3BfWr+OHj0KAAgGg2ravn37Esr56KOP1DTlHgKBQEI+bZqST7lPLdr69FDs2nvW3ou2nni/d+3apaZdu3Ytxj8AujF8FB/fffddNY1qYPR8VOrTTm4ovmoXDur5kEl0v+h1ddGnUB9//LF6XlxcDAC4fPmymqbc5Pnz0adSJSUlCAaD8PmiYcTOnj2LYDCIwsJCNU35IJUvMhD90mrrfeKJJwAA770XfYOkqKhIPZ+cjIR5y8/PBxD5B1DKVH5gALBkyRIAQG1trZp27lxkIdCBAwcS8gHA9evXE+xvvvlmTJq2Pm2acq/Hjh1Tr927dy+ASLzL+DTlr9Y+NDSklldQEJ2SO336NADgpZdeUtP8fj8AoLS0VE17//33AcT+2JTNHrQ/aMXHjo4ONe3mzZsJ+bT1Kfd64kQ0QpZSX1VVdDrw9dcjW65UV0cXeFVWZnf6+v8AWCq+kvErSTkAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}